#!/usr/bin/env python3
"""
Treinamento com Dados Reais do Banco veiculos_db
===============================================

Este script treina o modelo usando os relatos reais do banco veiculos_db.
Como nÃ£o temos labels verdadeiros, vamos usar heurÃ­sticas baseadas em palavras-chave
para criar labels automÃ¡ticos e depois treinar o modelo.
"""

import os
import sys
import json
import joblib
import psycopg
import pandas as pd
import numpy as np
from pathlib import Path
from typing import List, Tuple, Dict, Any
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, accuracy_score, precision_recall_curve
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
import warnings
warnings.filterwarnings('ignore')

# ConfiguraÃ§Ãµes
BASE_DIR = Path(__file__).parent.parent
MODELS_DIR = BASE_DIR / "ml_models" / "trained"
MODELS_DIR.mkdir(parents=True, exist_ok=True)

# ConfiguraÃ§Ã£o do banco veiculos_db
DB_CONFIG = {
    'host': 'localhost',
    'port': 5432,
    'dbname': 'veiculos_db',
    'user': 'postgres',
    'password': 'Jmkjmk.00'
}

class RealDataTrainer:
    """Treinador com dados reais do banco"""
    
    def __init__(self):
        self.model = None
        self.optimal_threshold = 0.35
        
        # Palavras-chave para classificaÃ§Ã£o automÃ¡tica
        self.suspeito_keywords = {
            # Comportamentos suspeitos
            'nervoso', 'nervosismo', 'agressivo', 'agressividade', 'mentiu', 'mentindo',
            'contradiÃ§Ã£o', 'contradiÃ§Ãµes', 'inconsistente', 'evasivo', 'evasÃ£o',
            
            # SituaÃ§Ãµes perigosas
            'manobra perigosa', 'manobra suspeita', 'fuga', 'tentou fugir', 'evadir',
            'mandado de prisÃ£o', 'foragido', 'procurado', 'flagrante',
            
            # Drogas e armas
            'droga', 'drogas', 'maconha', 'cocaÃ­na', 'crack', 'entorpecente',
            'arma', 'armas', 'pistola', 'revolver', 'muniÃ§Ã£o', 'disparo',
            
            # Crimes
            'roubo', 'furto', 'assalto', 'homicÃ­dio', 'assassinato', 'receptaÃ§Ã£o',
            'trÃ¡fico', 'traficante', 'contrabando', 'contrabandista',
            
            # Comportamentos especÃ­ficos
            'mÃ£o na cintura', 'odor de', 'cheiro de', 'substÃ¢ncia', 'produto',
            'dinheiro em espÃ©cie', 'grande quantidade', 'sem justificativa',
            'histÃ³ria inconsistente', 'documentaÃ§Ã£o irregular', 'documentos falsos'
        }
        
        self.normal_keywords = {
            # SituaÃ§Ãµes normais
            'verificaÃ§Ã£o de documentos', 'fiscalizaÃ§Ã£o de rotina', 'liberado',
            'nenhuma irregularidade', 'documentos em ordem', 'cnh vÃ¡lida',
            'visitando parentes', 'voltando de fÃ©rias', 'famÃ­lia',
            'trabalho', 'estudo', 'negÃ³cios', 'turismo', 'passeio',
            'documentaÃ§Ã£o em dia', 'seguro em dia', 'licenciamento'
        }
    
    def get_connection(self):
        """Cria conexÃ£o com banco"""
        try:
            return psycopg.connect(**DB_CONFIG)
        except Exception as e:
            print(f"âŒ Erro de conexÃ£o: {e}")
            return None
    
    def load_real_data(self, limit: int = 10000) -> Tuple[List[str], List[str]]:
        """Carrega dados reais do banco e cria labels automÃ¡ticos"""
        print(f"ðŸ”„ Carregando {limit} relatos do banco veiculos_db...")
        
        conn = self.get_connection()
        if not conn:
            return [], []
        
        textos = []
        labels = []
        
        try:
            with conn.cursor() as cur:
                cur.execute("""
                    SELECT relato, id 
                    FROM ocorrencias 
                    WHERE relato IS NOT NULL 
                    AND relato != '' 
                    AND LENGTH(relato) > 50
                    ORDER BY RANDOM()
                    LIMIT %s
                """, (limit,))
                
                for row in cur.fetchall():
                    relato, id_ocorrencia = row
                    if relato and len(relato.strip()) > 10:
                        textos.append(relato.strip())
                
                print(f"âœ… Carregados {len(textos)} relatos")
                
        except Exception as e:
            print(f"âŒ Erro ao carregar dados: {e}")
        finally:
            conn.close()
        
        # Criar labels automÃ¡ticos baseados em palavras-chave
        print("ðŸ·ï¸ Criando labels automÃ¡ticos...")
        labels = self.create_automatic_labels(textos)
        
        return textos, labels
    
    def create_automatic_labels(self, textos: List[str]) -> List[str]:
        """Cria labels automÃ¡ticos baseados em palavras-chave"""
        labels = []
        suspeito_count = 0
        normal_count = 0
        
        for texto in textos:
            texto_lower = texto.lower()
            
            # Contar palavras suspeitas
            suspeito_score = sum(1 for keyword in self.suspeito_keywords 
                               if keyword in texto_lower)
            
            # Contar palavras normais
            normal_score = sum(1 for keyword in self.normal_keywords 
                             if keyword in texto_lower)
            
            # Classificar baseado nos scores
            if suspeito_score > normal_score and suspeito_score > 0:
                labels.append('SUSPEITO')
                suspeito_count += 1
            else:
                labels.append('SEM_ALTERACAO')
                normal_count += 1
        
        print(f"ðŸ“Š Labels criados: {suspeito_count} SUSPEITO, {normal_count} SEM_ALTERACAO")
        return labels
    
    def find_optimal_threshold(self, X_test, y_test, model):
        """Encontra o threshold Ã³timo usando precision-recall curve"""
        # Converter labels para numÃ©rico
        label_map = {'SEM_ALTERACAO': 0, 'SUSPEITO': 1}
        y_test_num = [label_map[label] for label in y_test]
        
        # Obter probabilidades
        y_proba = model.predict_proba(X_test)[:, 1]
        
        # Calcular precision-recall curve
        precision, recall, thresholds = precision_recall_curve(y_test_num, y_proba, pos_label=1)
        
        # Encontrar threshold que maximiza F1-score
        f1_scores = 2 * (precision * recall) / (precision + recall + 1e-8)
        optimal_idx = np.argmax(f1_scores)
        optimal_threshold = thresholds[optimal_idx]
        
        print(f"ðŸŽ¯ Threshold Ã³timo encontrado: {optimal_threshold:.3f}")
        return optimal_threshold
    
    def train_model(self, textos: List[str], labels: List[str]) -> bool:
        """Treina o modelo com dados reais"""
        if len(textos) < 100:
            print("âŒ Dados insuficientes para treinamento")
            return False
        
        print(f"ðŸš€ Treinando modelo com {len(textos)} relatos reais...")
        
        # Dividir dados
        X_train, X_test, y_train, y_test = train_test_split(
            textos, labels, test_size=0.2, random_state=42, stratify=labels
        )
        
        # Criar pipeline otimizado para dados reais
        pipeline = Pipeline([
            ('tfidf', TfidfVectorizer(
                max_features=2000,  # Mais features para dados reais
                ngram_range=(1, 3),
                stop_words=None,
                min_df=2,  # Ignorar palavras muito raras
                max_df=0.8,  # Ignorar palavras muito comuns
                sublinear_tf=True
            )),
            ('scaler', StandardScaler(with_mean=False)),
            ('classifier', RandomForestClassifier(
                n_estimators=300,  # Mais Ã¡rvores para dados reais
                random_state=42,
                class_weight='balanced',
                max_depth=15,
                min_samples_split=3,
                min_samples_leaf=1
            ))
        ])
        
        # Treinar
        pipeline.fit(X_train, y_train)
        
        # Encontrar threshold Ã³timo
        self.optimal_threshold = self.find_optimal_threshold(X_test, y_test, pipeline)
        
        # Avaliar com threshold Ã³timo
        y_proba = pipeline.predict_proba(X_test)[:, 1]
        y_pred_optimal = (y_proba >= self.optimal_threshold).astype(int)
        
        # Converter labels para numÃ©rico para avaliaÃ§Ã£o
        label_map = {'SEM_ALTERACAO': 0, 'SUSPEITO': 1}
        y_test_num = [label_map[label] for label in y_test]
        
        accuracy = accuracy_score(y_test_num, y_pred_optimal)
        
        print(f"ðŸ“Š AcurÃ¡cia com threshold Ã³timo: {accuracy:.3f}")
        print("\nðŸ“‹ RelatÃ³rio de ClassificaÃ§Ã£o:")
        print(classification_report(y_test_num, y_pred_optimal, 
                                  target_names=['SEM_ALTERACAO', 'SUSPEITO']))
        
        # Cross-validation
        print("\nðŸ”„ ValidaÃ§Ã£o cruzada...")
        cv_scores = cross_val_score(pipeline, textos, labels, cv=5, scoring='f1_macro')
        print(f"ðŸ“Š CV F1-Score: {cv_scores.mean():.3f} Â± {cv_scores.std():.3f}")
        
        # Salvar modelo
        self.model = pipeline
        self.save_model()
        
        return True
    
    def save_model(self):
        """Salva o modelo treinado"""
        if not self.model:
            print("âŒ Nenhum modelo para salvar")
            return
        
        # Salvar modelo
        model_path = MODELS_DIR / "semantic_agents_clf.joblib"
        joblib.dump(self.model, model_path)
        print(f"âœ… Modelo salvo em: {model_path}")
        
        # Salvar metadados
        metadata = {
            'model_type': 'RandomForestClassifier',
            'features': 'TF-IDF',
            'training_date': pd.Timestamp.now().isoformat(),
            'version': '3.0.0',
            'description': 'Modelo treinado com dados reais do veiculos_db',
            'optimal_threshold': self.optimal_threshold,
            'ngram_range': '(1, 3)',
            'max_features': 2000,
            'data_source': 'veiculos_db.ocorrencias',
            'training_samples': len(self.model.named_steps['classifier'].estimators_)
        }
        
        metadata_path = MODELS_DIR / "semantic_agents_metadata.json"
        with open(metadata_path, 'w', encoding='utf-8') as f:
            json.dump(metadata, f, indent=2, ensure_ascii=False)
        
        print(f"âœ… Metadados salvos em: {metadata_path}")
        print(f"ðŸŽ¯ Threshold Ã³timo salvo: {self.optimal_threshold:.3f}")
    
    def test_model(self):
        """Testa o modelo treinado"""
        if not self.model:
            print("âŒ Nenhum modelo carregado")
            return
        
        test_cases = [
            "VeÃ­culo abordado apÃ³s realizar manobra perigosa. Durante a entrevista, o motorista mentiu sobre o destino",
            "FiscalizaÃ§Ã£o de rotina. Tratava-se de uma famÃ­lia voltando de fÃ©rias. Nenhuma irregularidade foi encontrada",
            "Ocupantes demonstraram nervosismo ao avistar a viatura. Durante a entrevista, o passageiro manteve a mÃ£o na cintura",
            "VeÃ­culo parado para verificaÃ§Ã£o de documentos. O motorista estava indo visitar parentes. ApÃ³s a verificaÃ§Ã£o, foi liberado",
            "DenÃºncia anÃ´nima informou sobre um carro suspeito. Durante a entrevista, foi localizada uma grande quantidade de dinheiro sem justificativa"
        ]
        
        print(f"\nðŸ§ª Testando modelo (threshold: {self.optimal_threshold:.3f}):")
        for texto in test_cases:
            proba = self.model.predict_proba([texto])[0]
            suspeito_prob = proba[1] if len(proba) > 1 else proba[0]
            pred = "SUSPEITO" if suspeito_prob >= self.optimal_threshold else "SEM_ALTERACAO"
            print(f"   '{texto[:60]}...' â†’ {pred} ({suspeito_prob:.2f})")

def main():
    """FunÃ§Ã£o principal"""
    print("ðŸ¤– TREINAMENTO COM DADOS REAIS - veiculos_db")
    print("=" * 60)
    
    trainer = RealDataTrainer()
    
    # Carregar dados reais
    textos, labels = trainer.load_real_data(10000)  # 10k relatos
    
    if len(textos) < 100:
        print("âŒ Dados insuficientes")
        return
    
    # Treinar modelo
    success = trainer.train_model(textos, labels)
    
    if success:
        trainer.test_model()
        print("\nâœ… Treinamento com dados reais concluÃ­do com sucesso!")
        print("ðŸŽ¯ O modelo agora foi treinado com dados reais do banco!")
    else:
        print("\nâŒ Falha no treinamento")

if __name__ == "__main__":
    main()

