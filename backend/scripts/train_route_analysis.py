#!/usr/bin/env python3
"""
Treinamento de An√°lise de Rotas e Padr√µes de Viagem
==================================================

Este script analisa rotas de ve√≠culos para detectar padr√µes de viagens il√≠citas,
incluindo ida e volta, frequ√™ncia, hor√°rios suspeitos e trajetos conhecidos.
"""

import os
import sys
import json
import joblib
import psycopg
import pandas as pd
import numpy as np
from pathlib import Path
from typing import List, Tuple, Dict, Any, Set
from datetime import datetime, timedelta
from collections import defaultdict, Counter
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, accuracy_score, precision_recall_curve
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler, LabelEncoder
import warnings
warnings.filterwarnings('ignore')

# Configura√ß√µes
BASE_DIR = Path(__file__).parent.parent
MODELS_DIR = BASE_DIR / "ml_models" / "trained"
MODELS_DIR.mkdir(parents=True, exist_ok=True)

# Configura√ß√£o do banco veiculos_db
DB_CONFIG = {
    'host': 'localhost',
    'port': 5432,
    'dbname': 'veiculos_db',
    'user': 'postgres',
    'password': 'Jmkjmk.00'
}

class RouteAnalysisTrainer:
    """Treinador especializado em an√°lise de rotas e padr√µes de viagem"""
    
    def __init__(self):
        self.model = None
        self.optimal_threshold = 0.35
        self.route_patterns = {}
        self.vehicle_history = defaultdict(list)
        
        # ROTAS CONHECIDAS COMO SUSPEITAS (fronteiras, √°reas de risco)
        self.suspicious_routes = {
            'fronteira', 'fronteira brasil', 'fronteira argentina', 'fronteira paraguai',
            'fronteira uruguai', 'fronteira bol√≠via', 'fronteira col√¥mbia',
            'tri√¢ngulo das bermudas', 'regi√£o do pantanal', 'mato grosso do sul',
            'rio grande do sul', 'santa catarina', 'paran√°', 's√£o paulo',
            'rio de janeiro', 'minas gerais', 'goi√°s', 'mato grosso',
            'acre', 'rond√¥nia', 'amazonas', 'roraima', 'amap√°', 'par√°'
        }
        
        # HOR√ÅRIOS SUSPEITOS (madrugada, hor√°rios n√£o comerciais)
        self.suspicious_hours = {
            '00:00', '01:00', '02:00', '03:00', '04:00', '05:00',
            '22:00', '23:00', '23:30', '00:30', '01:30', '02:30'
        }
        
        # PADR√ïES DE IDA E VOLTA SUSPEITOS
        self.round_trip_patterns = {
            'ida e volta', 'ida e retorno', 'ida volta', 'ida retorno',
            'mesmo dia', 'mesmo trajeto', 'trajeto id√™ntico', 'rota id√™ntica',
            'frequ√™ncia alta', 'muitas viagens', 'viagens constantes'
        }
        
        # INDICADORES DE VIAGEM IL√çCITA
        self.illicit_travel_indicators = {
            'sem destino claro', 'destino incerto', 'sem justificativa',
            'viagem sem motivo', 'sem explica√ß√£o', 'destino suspeito',
            'rota incomum', 'trajeto estranho', 'caminho suspeito',
            'frequ√™ncia suspeita', 'padr√£o estranho', 'comportamento repetitivo'
        }
        
        # √ÅREAS DE ALTO RISCO (conhecidas por tr√°fico, contrabando)
        self.high_risk_areas = {
            'fronteira seca', '√°rea de risco', 'zona de conflito',
            'regi√£o perigosa', '√°rea suspeita', 'local de risco',
            'ponto de tr√°fico', '√°rea de contrabando', 'zona de drogas'
        }
    
    def get_connection(self):
        """Cria conex√£o com banco"""
        try:
            return psycopg.connect(**DB_CONFIG)
        except Exception as e:
            print(f"‚ùå Erro de conex√£o: {e}")
            return None
    
    def load_route_data(self, limit: int = 30000) -> Tuple[List[Dict], List[str]]:
        """Carrega dados de rotas e cria labels baseadas em padr√µes"""
        print(f"üîÑ Carregando {limit} ocorr√™ncias com dados de rota...")
        
        conn = self.get_connection()
        if not conn:
            return [], []
        
        route_data = []
        labels = []
        
        try:
            with conn.cursor() as cur:
                # Buscar ocorr√™ncias com informa√ß√µes de rota, localiza√ß√£o e hor√°rio
                cur.execute("""
                    SELECT 
                        o.relato,
                        o.datahora,
                        o.datahora_fim,
                        o.ocupantes,
                        o.presos,
                        o.veiculos,
                        o.id as ocorrencia_id,
                        v.placa,
                        v.marca_modelo,
                        v.tipo,
                        v.ano_modelo,
                        v.cor,
                        v.local_emplacamento,
                        v.transferencia_recente,
                        v.comunicacao_venda,
                        v.crime_prf,
                        v.abordagem_prf
                    FROM ocorrencias o
                    LEFT JOIN veiculos v ON o.veiculo_id = v.id
                    WHERE o.relato IS NOT NULL 
                    AND o.relato != '' 
                    AND LENGTH(o.relato) > 30
                    ORDER BY RANDOM()
                    LIMIT %s
                """, (limit,))
                
                for row in cur.fetchall():
                    relato, datahora, datahora_fim, ocupantes, presos, veiculos, \
                    ocorrencia_id, placa, marca_modelo, tipo, ano_modelo, cor, \
                    local_emplacamento, transferencia_recente, comunicacao_venda, \
                    crime_prf, abordagem_prf = row
                    
                    if relato and len(relato.strip()) > 10:
                        route_info = {
                            'relato': relato.strip(),
                            'datahora': datahora,
                            'datahora_fim': datahora_fim,
                            'ocupantes': ocupantes,
                            'presos': presos,
                            'veiculos': veiculos,
                            'ocorrencia_id': ocorrencia_id,
                            'placa': placa,
                            'marca_modelo': marca_modelo,
                            'tipo': tipo,
                            'ano_modelo': ano_modelo,
                            'cor': cor,
                            'local_emplacamento': local_emplacamento,
                            'transferencia_recente': transferencia_recente,
                            'comunicacao_venda': comunicacao_venda,
                            'crime_prf': crime_prf,
                            'abordagem_prf': abordagem_prf
                        }
                        route_data.append(route_info)
                
                print(f"‚úÖ Carregados {len(route_data)} ocorr√™ncias com dados de rota")
                
        except Exception as e:
            print(f"‚ùå Erro ao carregar dados: {e}")
        finally:
            conn.close()
        
        # Analisar padr√µes de rota e criar labels
        print("üß† Analisando padr√µes de rota e criando labels...")
        labels = self.analyze_route_patterns(route_data)
        
        return route_data, labels
    
    def analyze_route_patterns(self, route_data: List[Dict]) -> List[str]:
        """Analisa padr√µes de rota para criar labels inteligentes"""
        labels = []
        suspeito_count = 0
        normal_count = 0
        
        # Agrupar por placa para analisar hist√≥rico
        vehicle_groups = defaultdict(list)
        for i, data in enumerate(route_data):
            if data['placa']:
                vehicle_groups[data['placa']].append((i, data))
        
        print(f"üìä Analisando {len(vehicle_groups)} ve√≠culos √∫nicos...")
        
        for i, data in enumerate(route_data):
            # Calcular score de suspei√ß√£o baseado em padr√µes de rota
            suspicion_score = self.calculate_route_suspicion(data, vehicle_groups)
            
            # Classificar baseado no score (mais seletivo)
            if suspicion_score > 0.3:  # Threshold ajustado para scores menores
                labels.append('SUSPEITO')
                suspeito_count += 1
            else:
                labels.append('SEM_ALTERACAO')
                normal_count += 1
        
        print(f"üìä Labels de rota: {suspeito_count} SUSPEITO, {normal_count} SEM_ALTERACAO")
        return labels
    
    def calculate_route_suspicion(self, data: Dict, vehicle_groups: Dict) -> float:
        """Calcula suspei√ß√£o baseada em padr√µes de rota"""
        score = 0.0
        relato_lower = data['relato'].lower()
        
        # 1. AN√ÅLISE DE LOCALIZA√á√ÉO
        location_score = 0.0
        if data['local_emplacamento']:
            local_lower = data['local_emplacamento'].lower()
            if any(area in local_lower for area in self.suspicious_routes):
                location_score += 0.3
        
        # 2. AN√ÅLISE DE HOR√ÅRIO
        time_score = 0.0
        if data['datahora']:
            hora_str = str(data['datahora'])
            if any(hora in hora_str for hora in self.suspicious_hours):
                time_score += 0.2
        
        # 3. AN√ÅLISE DE PADR√ïES DE IDA E VOLTA
        round_trip_score = 0.0
        if any(pattern in relato_lower for pattern in self.round_trip_patterns):
            round_trip_score += 0.3
        
        # 4. AN√ÅLISE DE INDICADORES DE VIAGEM IL√çCITA
        illicit_score = 0.0
        if any(indicator in relato_lower for indicator in self.illicit_travel_indicators):
            illicit_score += 0.2
        
        # 5. AN√ÅLISE DE √ÅREAS DE ALTO RISCO
        risk_area_score = 0.0
        if any(area in relato_lower for area in self.high_risk_areas):
            risk_area_score += 0.3
        
        # 6. AN√ÅLISE DE HIST√ìRICO DO VE√çCULO (frequ√™ncia, padr√µes)
        history_score = 0.0
        if data['placa'] and data['placa'] in vehicle_groups:
            vehicle_history = vehicle_groups[data['placa']]
            if len(vehicle_history) > 5:  # Ve√≠culo com muitas ocorr√™ncias
                history_score += 0.2
            
            # Verificar se h√° padr√µes de ida e volta
            if len(vehicle_history) > 2:
                # Analisar se h√° ocorr√™ncias em locais similares
                locations = [h[1]['local_emplacamento'] for h in vehicle_history if h[1]['local_emplacamento']]
                if len(set(locations)) < len(locations) * 0.5:  # Muitos locais repetidos
                    history_score += 0.3
        
        # 7. AN√ÅLISE DE INDICADORES ESPEC√çFICOS DO VE√çCULO
        vehicle_score = 0.0
        # Ajustar scores baseado no contexto do relato
        if data['crime_prf']:  # Ve√≠culo com hist√≥rico de crime
            # S√≥ adicionar score se o relato mencionar comportamento suspeito
            if any(word in relato_lower for word in ['suspeito', 'nervoso', 'mentiu', 'contradi√ß√£o', 'evadir', 'fuga']):
                vehicle_score += 0.3
        if data['abordagem_prf']:  # Ve√≠culo com hist√≥rico de abordagem
            # S√≥ adicionar score se houver padr√µes suspeitos no relato
            if any(word in relato_lower for word in ['frequ√™ncia', 'muitas vezes', 'repetido', 'constante']):
                vehicle_score += 0.2
        if data['transferencia_recente']:  # Transfer√™ncia recente (suspeito)
            vehicle_score += 0.2
        
        # Score final
        total_score = location_score + time_score + round_trip_score + illicit_score + risk_area_score + history_score + vehicle_score
        
        # Normalizar entre 0 e 1
        return min(max(total_score, 0.0), 1.0)
    
    def create_route_features(self, route_data: List[Dict]) -> List[str]:
        """Cria features espec√≠ficas para an√°lise de rotas"""
        enhanced_texts = []
        
        for data in route_data:
            relato_lower = data['relato'].lower()
            enhanced_text = data['relato']
            
            # Adicionar informa√ß√µes de localiza√ß√£o
            if data['local_emplacamento']:
                enhanced_text += f" [LOCAL_EMPLACAMENTO:{data['local_emplacamento']}]"
            
            # Adicionar informa√ß√µes de hor√°rio
            if data['datahora']:
                enhanced_text += f" [DATAHORA:{data['datahora']}]"
            
            # Adicionar informa√ß√µes do ve√≠culo
            if data['placa']:
                enhanced_text += f" [PLACA:{data['placa']}]"
            if data['marca_modelo']:
                enhanced_text += f" [MARCA_MODELO:{data['marca_modelo']}]"
            if data['cor']:
                enhanced_text += f" [COR:{data['cor']}]"
            if data['tipo']:
                enhanced_text += f" [TIPO:{data['tipo']}]"
            
            # Adicionar indicadores espec√≠ficos do ve√≠culo
            if data['crime_prf']:
                enhanced_text += f" [CRIME_PRF:{data['crime_prf']}]"
            if data['abordagem_prf']:
                enhanced_text += f" [ABORDAGEM_PRF:{data['abordagem_prf']}]"
            if data['transferencia_recente']:
                enhanced_text += f" [TRANSFERENCIA_RECENTE:{data['transferencia_recente']}]"
            
            # Marcar rotas suspeitas
            for route in self.suspicious_routes:
                if route in relato_lower:
                    enhanced_text += f" [ROTA_SUSPEITA:{route}]"
            
            # Marcar hor√°rios suspeitos
            if data['datahora']:
                hora_str = str(data['datahora'])
                if any(hora in hora_str for hora in self.suspicious_hours):
                    enhanced_text += f" [HORARIO_SUSPEITO:{hora_str}]"
            
            # Marcar padr√µes de ida e volta
            for pattern in self.round_trip_patterns:
                if pattern in relato_lower:
                    enhanced_text += f" [IDA_VOLTA:{pattern}]"
            
            # Marcar indicadores de viagem il√≠cita
            for indicator in self.illicit_travel_indicators:
                if indicator in relato_lower:
                    enhanced_text += f" [VIAGEM_ILICITA:{indicator}]"
            
            # Marcar √°reas de alto risco
            for area in self.high_risk_areas:
                if area in relato_lower:
                    enhanced_text += f" [AREA_RISCO:{area}]"
            
            enhanced_texts.append(enhanced_text)
        
        return enhanced_texts
    
    def find_optimal_threshold(self, X_test, y_test, model):
        """Encontra o threshold √≥timo usando precision-recall curve"""
        # Converter labels para num√©rico
        label_map = {'SEM_ALTERACAO': 0, 'SUSPEITO': 1}
        y_test_num = [label_map[label] for label in y_test]
        
        # Obter probabilidades
        y_proba = model.predict_proba(X_test)[:, 1]
        
        # Calcular precision-recall curve
        precision, recall, thresholds = precision_recall_curve(y_test_num, y_proba, pos_label=1)
        
        # Encontrar threshold que maximiza F1-score
        f1_scores = 2 * (precision * recall) / (precision + recall + 1e-8)
        optimal_idx = np.argmax(f1_scores)
        optimal_threshold = thresholds[optimal_idx]
        
        print(f"üéØ Threshold √≥timo encontrado: {optimal_threshold:.3f}")
        return optimal_threshold
    
    def train_model(self, route_data: List[Dict], labels: List[str]) -> bool:
        """Treina o modelo de an√°lise de rotas"""
        if len(route_data) < 100:
            print("‚ùå Dados insuficientes para treinamento")
            return False
        
        print(f"üöÄ Treinando modelo de an√°lise de rotas com {len(route_data)} ocorr√™ncias...")
        
        # Criar features espec√≠ficas de rota
        enhanced_texts = self.create_route_features(route_data)
        
        # Dividir dados
        X_train, X_test, y_train, y_test = train_test_split(
            enhanced_texts, labels, test_size=0.2, random_state=42, stratify=labels
        )
        
        # Criar pipeline otimizado para an√°lise de rotas
        pipeline = Pipeline([
            ('tfidf', TfidfVectorizer(
                max_features=5000,  # Mais features para an√°lise de rotas
                ngram_range=(1, 5),  # Incluir 5-gramas para capturar padr√µes complexos
                stop_words=None,
                min_df=2,
                max_df=0.7,
                sublinear_tf=True,
                analyzer='word'
            )),
            ('scaler', StandardScaler(with_mean=False)),
            ('classifier', GradientBoostingClassifier(
                n_estimators=800,  # Mais √°rvores para padr√µes complexos
                random_state=42,
                learning_rate=0.1,
                max_depth=20,
                min_samples_split=2,
                min_samples_leaf=1,
                subsample=0.8
            ))
        ])
        
        # Treinar
        pipeline.fit(X_train, y_train)
        
        # Encontrar threshold √≥timo
        self.optimal_threshold = self.find_optimal_threshold(X_test, y_test, pipeline)
        
        # Avaliar com threshold √≥timo
        y_proba = pipeline.predict_proba(X_test)[:, 1]
        y_pred_optimal = (y_proba >= self.optimal_threshold).astype(int)
        
        # Converter labels para num√©rico para avalia√ß√£o
        label_map = {'SEM_ALTERACAO': 0, 'SUSPEITO': 1}
        y_test_num = [label_map[label] for label in y_test]
        
        accuracy = accuracy_score(y_test_num, y_pred_optimal)
        
        print(f"üìä Acur√°cia com threshold √≥timo: {accuracy:.3f}")
        print("\nüìã Relat√≥rio de Classifica√ß√£o:")
        print(classification_report(y_test_num, y_pred_optimal, 
                                  target_names=['SEM_ALTERACAO', 'SUSPEITO']))
        
        # Cross-validation
        print("\nüîÑ Valida√ß√£o cruzada...")
        cv_scores = cross_val_score(pipeline, enhanced_texts, labels, cv=5, scoring='f1_macro')
        print(f"üìä CV F1-Score: {cv_scores.mean():.3f} ¬± {cv_scores.std():.3f}")
        
        # Salvar modelo
        self.model = pipeline
        self.save_model()
        
        return True
    
    def save_model(self):
        """Salva o modelo de an√°lise de rotas"""
        if not self.model:
            print("‚ùå Nenhum modelo para salvar")
            return
        
        # Salvar modelo
        model_path = MODELS_DIR / "route_analysis_clf.joblib"
        joblib.dump(self.model, model_path)
        print(f"‚úÖ Modelo de an√°lise de rotas salvo em: {model_path}")
        
        # Salvar metadados
        metadata = {
            'model_type': 'GradientBoostingClassifier_RouteAnalysis',
            'features': 'TF-IDF_Route_Patterns',
            'training_date': pd.Timestamp.now().isoformat(),
            'version': '1.0.0',
            'description': 'Modelo especializado em an√°lise de rotas e padr√µes de viagem',
            'optimal_threshold': self.optimal_threshold,
            'ngram_range': '(1, 5)',
            'max_features': 5000,
            'data_source': 'veiculos_db.ocorrencias',
            'route_analysis': True,
            'suspicious_routes': list(self.suspicious_routes),
            'suspicious_hours': list(self.suspicious_hours),
            'round_trip_patterns': list(self.round_trip_patterns),
            'illicit_travel_indicators': list(self.illicit_travel_indicators),
            'high_risk_areas': list(self.high_risk_areas)
        }
        
        metadata_path = MODELS_DIR / "route_analysis_metadata.json"
        with open(metadata_path, 'w', encoding='utf-8') as f:
            json.dump(metadata, f, indent=2, ensure_ascii=False)
        
        print(f"‚úÖ Metadados de an√°lise de rotas salvos em: {metadata_path}")
        print(f"üéØ Threshold √≥timo salvo: {self.optimal_threshold:.3f}")
    
    def test_route_model(self):
        """Testa o modelo de an√°lise de rotas com casos espec√≠ficos"""
        if not self.model:
            print("‚ùå Nenhum modelo carregado")
            return
        
        test_cases = [
            # Caso que DEVE ser SUSPEITO (rota de fronteira + hor√°rio suspeito)
            {
                'texto': "Abordagem em ve√≠culo vindo da fronteira com Argentina. Ocorr√™ncia registrada √†s 02:30 da madrugada. Motorista sem justificativa clara para a viagem.",
                'expected': 'SUSPEITO',
                'description': 'Fronteira + hor√°rio suspeito + sem justificativa'
            },
            # Caso que DEVE ser SUSPEITO (padr√£o de ida e volta)
            {
                'texto': "Ve√≠culo com frequ√™ncia alta de viagens entre S√£o Paulo e Mato Grosso do Sul. Mesmo trajeto repetido v√°rias vezes no mesmo dia.",
                'expected': 'SUSPEITO',
                'description': 'Frequ√™ncia alta + mesmo trajeto + ida e volta'
            },
            # Caso que DEVE ser SUSPEITO (√°rea de alto risco)
            {
                'texto': "Abordagem em regi√£o conhecida por tr√°fico de drogas. Ve√≠culo com comportamento suspeito e sem destino claro.",
                'expected': 'SUSPEITO',
                'description': '√Årea de alto risco + sem destino claro'
            },
            # Caso que DEVE ser SEM_ALTERACAO (viagem normal)
            {
                'texto': "Fiscaliza√ß√£o de rotina em ve√≠culo de empresa de entregas. Carga conforme nota fiscal e destino comercial leg√≠timo.",
                'expected': 'SEM_ALTERACAO',
                'description': 'Viagem comercial leg√≠tima'
            },
            # Caso que DEVE ser SEM_ALTERACAO (viagem familiar)
            {
                'texto': "Fam√≠lia voltando de f√©rias. Documenta√ß√£o em ordem e destino residencial confirmado.",
                'expected': 'SEM_ALTERACAO',
                'description': 'Viagem familiar leg√≠tima'
            }
        ]
        
        print(f"\nüß™ Testando modelo de an√°lise de rotas (threshold: {self.optimal_threshold:.3f}):")
        correct = 0
        
        for i, caso in enumerate(test_cases, 1):
            # Criar features espec√≠ficas de rota
            enhanced_text = self.create_route_features([{'relato': caso['texto']}])[0]
            
            proba = self.model.predict_proba([enhanced_text])[0]
            suspeito_prob = proba[1] if len(proba) > 1 else proba[0]
            pred = "SUSPEITO" if suspeito_prob >= self.optimal_threshold else "SEM_ALTERACAO"
            
            is_correct = pred == caso['expected']
            status = "‚úÖ" if is_correct else "‚ùå"
            
            if is_correct:
                correct += 1
            
            print(f"\n{status} CASO {i}: {caso['description']}")
            print(f"   Esperado: {caso['expected']} | Obtido: {pred} ({suspeito_prob:.3f})")
            print(f"   Texto: {caso['texto'][:80]}...")
        
        print(f"\nüìä RESULTADO GERAL: {correct}/{len(test_cases)} corretos ({correct/len(test_cases)*100:.1f}%)")

def main():
    """Fun√ß√£o principal"""
    print("üó∫Ô∏è TREINAMENTO DE AN√ÅLISE DE ROTAS E PADR√ïES DE VIAGEM")
    print("=" * 70)
    
    trainer = RouteAnalysisTrainer()
    
    # Carregar dados de rotas
    route_data, labels = trainer.load_route_data(30000)  # 30k ocorr√™ncias
    
    if len(route_data) < 100:
        print("‚ùå Dados insuficientes")
        return
    
    # Treinar modelo de an√°lise de rotas
    success = trainer.train_model(route_data, labels)
    
    if success:
        trainer.test_route_model()
        print("\n‚úÖ Treinamento de an√°lise de rotas conclu√≠do com sucesso!")
        print("üó∫Ô∏è O modelo agora detecta padr√µes de viagens il√≠citas!")
    else:
        print("\n‚ùå Falha no treinamento")

if __name__ == "__main__":
    main()
